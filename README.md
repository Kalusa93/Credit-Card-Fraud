
# Detecci√≥n de Fraude en Tarjetas de Cr√©dito

Este proyecto tiene como objetivo **detectar transacciones fraudulentas** en un dataset real de Kaggle utilizando modelos de Machine Learning.

## üìÇ Dataset
- Fuente: [Credit Card Fraud Detection - Kaggle](https://www.kaggle.com/mlg-ulb/creditcardfraud)
- Contiene **284,807 transacciones** realizadas en septiembre de 2013 por clientes con tarjetas de cr√©dito en Europa. Las transacciones fueron realizadas en el plazo de 2 d√≠as.
- Las variables V1, V2, ... V28 no se revelan por motivos de confidencialidad.
- Cada fila representa una transacci√≥n, con:
  - Variables num√©ricas transformadas mediante *PCA* (`V1, V2, ‚Ä¶ V28`).
  - `Amount`: monto de la transacci√≥n.
  - `Time`: segundos transcurridos desde la primera transacci√≥n.
  - `Class`: etiqueta objetivo (0 = No Fraude, 1 = Fraude).
- Solo el **0.172%** de las transacciones corresponden a fraude ‚Üí dataset altamente **desbalanceado**.

## ‚öôÔ∏è Preprocesamiento
1. Normalizaci√≥n de la variable `Amount`.
2. Escalado de la variable `Time`.
3. Mezcla (*shuffle*) del dataset para evitar sesgos en el orden.
4. Divisi√≥n en:
   - **Entrenamiento**: 240,000 transacciones.
   - **Validaci√≥n**: 22,000 transacciones.
   - **Prueba**: 22,000 transacciones.

## üß† Modelos aplicados
- **Regresi√≥n Log√≠stica**
  - Buen desempe√±o en la clase mayoritaria (*Not Fraud*).
  - Baja capacidad de detecci√≥n de fraudes en dataset original (recall limitado).
- **Red Neuronal Simple**
  - Arquitectura sencilla: capas densas con activaci√≥n *ReLU* y salida *sigmoide*.
  - Accuracy global muy alto (>99%), pero esta m√©trica no refleja bien la detecci√≥n de fraudes debido al desbalance.
- **Random Forest**
  - Mejor capacidad de modelar relaciones no lineales.
  - Rendimiento superior en recall comparado con Logistic Regression.
- **Gradient Boosting**
  - Algoritmo de boosting que combina m√∫ltiples clasificadores d√©biles.
  - Destacado en mejorar el balance entre precisi√≥n y recall en fraudes.

## üìä Resultados

### Dataset original (muy desbalanceado)
- **Accuracy**: muy alto (>99%).
- **Recall en fraudes**: bajo ‚Üí el modelo ignora gran parte de los casos positivos.
- **Conclusi√≥n**: los modelos se sesgan fuertemente hacia la clase mayoritaria (not Fraud).

### Dataset balanceado (undersampling)
- Se cre√≥ un dataset balanceado con igual cantidad de fraudes y no fraudes.
- **Resultados:**
  - **Precisi√≥n, recall y f1-score** para la clase *Fraud* mejoran notablemente en todos los modelos.
  - Los modelos logran identificar fraudes con mucha mayor efectividad.
- **Conclusi√≥n**: el balanceo es clave para entrenar modelos que realmente detecten anomal√≠as en este tipo de problemas. Los algoritmos m√°s precisos fueron la regresi√≥n log√≠stica y  red neuronal con RELU + Sigmoide, con m√©tricas precision, recall y f1-score superiores al 95%, seguidos por los algoritmos random forest y gradient boosting.

---

üìå **Conclusi√≥n general**:  
Con el dataset desbalanceado, los modelos muestran un *accuracy* enga√±osamente alto pero casi no detectan fraudes.  
Cuando el dataset se balancea, la **detecci√≥n de fraudes mejora dr√°sticamente**, con m√©tricas de *precision, recall y f1-score* mucho m√°s representativas y √∫tiles para un caso real.
